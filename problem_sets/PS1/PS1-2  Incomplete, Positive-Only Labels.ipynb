{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ccda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\cs229-journey\\cs229-journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42945aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import problem_sets.PS1.src.util as util\n",
    "\n",
    "from problem_sets.PS1.src.linear_model import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3_training_set_path = 'data/ds3_train.csv'\n",
    "ds3_valid_set_path = 'data/ds3_valid.csv'\n",
    "ds3_test_set_path = 'data/ds3_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0933a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = util.load_dataset('data/ds3_train.csv', add_intercept=True)\n",
    "_, t_train = util.load_dataset('data/ds3_train.csv', label_col='t')\n",
    "x_valid, y_valid = util.load_dataset('data/ds3_valid.csv', add_intercept=True)\n",
    "_, t_valid = util.load_dataset('data/ds3_valid.csv', label_col='t')\n",
    "x_test, y_test = util.load_dataset('data/ds3_test.csv', add_intercept=True)\n",
    "_, t_test = util.load_dataset('data/ds3_test.csv', label_col='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c758a92b",
   "metadata": {},
   "source": [
    "We have a look to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[:,1], x_train[:,2], \"x\", label = \"Train Data\")\n",
    "plt.plot(x_test[:,1], x_test[:,2], \".\", label = \"Validation Data\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test[:,1][t_test == 1], x_test[:,2][t_test == 1], \"x\", label = \"Features with true label = 1\")\n",
    "plt.plot(x_test[:,1][t_test == 0], x_test[:,2][t_test == 0], \".\", label = \"Features with true label = 0\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a264d05",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "As we see given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4aea7",
   "metadata": {},
   "source": [
    " c) First we will consider the ideal case, where we have access to the true t-labels for training.\n",
    " In src/p02cde_posonly, write a logistic regression classi er that uses $x_1$ and $x_2$ as input\n",
    " features, and train it using the t-labels (you can ignore the y-labels for this part). Output\n",
    " the trained models predictions on the test set to the le specified in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the logistic regression model we made before\n",
    "class LogisticRegression(LinearModel):\n",
    "    \"\"\"Logistic regression with Newton's Method as the solver.\n",
    "\n",
    "    Example usage:\n",
    "        > clf = LogisticRegression()\n",
    "        > clf.fit(x_train, y_train)\n",
    "        > clf.predict(x_eval)\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Run Newton's Method to minimize J(theta) for logistic regression.\n",
    "\n",
    "        :param x: Training example inputs. Shape (m, n).\n",
    "        :param y: Training example labels. Shape (m,).\n",
    "        \"\"\"\n",
    "        def sigmoid(theta):\n",
    "            return 1/(1+np.exp(-np.dot(x, theta)))\n",
    "        \n",
    "        def gradient_loss(theta):\n",
    "            return -np.dot(x.T, (y - sigmoid(theta)))/m\n",
    "        \n",
    "        def hessian(theta):\n",
    "            h_theta_x = np.reshape(sigmoid(theta), (-1, 1))\n",
    "            return 1 / m * np.dot(x.T, h_theta_x * (1 - h_theta_x) * x)\n",
    "        \n",
    "        def newton_step(H, gradient, theta):\n",
    "            return theta - np.dot(np.linalg.inv(H), gradient)\n",
    "        \n",
    "        m, n = x.shape\n",
    "\n",
    "        self.theta = np.zeros(n)\n",
    "        while True:\n",
    "            theta = np.copy(self.theta)\n",
    "            gradient = gradient_loss(theta)\n",
    "            H = hessian(theta)\n",
    "            self.theta = newton_step(H, gradient, theta)\n",
    "            if np.linalg.norm(self.theta - theta) < self.eps:\n",
    "                break\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Make a prediction given new inputs x.\n",
    "\n",
    "        :param x: Inputs of shape (m, n).\n",
    "        :return:  Outputs of shape (m,).\n",
    "        \"\"\"\n",
    "        probs = 1/(1+np.exp(-np.dot(x, self.theta)))\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(eps = 1e-5)\n",
    "model.fit(x_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = np.mean((model.predict(x_train) > 0.5) == t_train)\n",
    "print(f\"The accuracy over the train set has been {accuracy_train:.2%}\")\n",
    "util.plot(x_train, t_train, theta=model.theta)\n",
    "plt.legend((\"t=1\", \"t=0\", \"Decision Boundary\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875955f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = np.mean((model.predict(x_test) > 0.5) == t_test)\n",
    "print(f\"The accuracy over the test set has been {accuracy_test:.2%}\")\n",
    "util.plot(x_test, t_test, theta=model.theta)\n",
    "plt.legend((\"t=1\", \"t=0\", \"Decision Boundary\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc0bdb",
   "metadata": {},
   "source": [
    "(d) We now consider the case where the t-labels are unavail\n",
    "able, so you only have access to the y-labels at training time. Add to your code in\n",
    " p02cde_posonly.py to re-train the classi er (still using $x_1$ and $x_2$ as input features), but\n",
    " using the y-labels only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[:, 1][y_train == 1], x_train[:, 2][y_train == 1], \"x\", label = \"Features with y label = 1\")\n",
    "plt.plot(x_test[:, 1][y_test == 0], x_test[:, 2][y_test == 0], \".\", label = \"Features with y label = 0\")\n",
    "plt.plot(x_test[:, 1][t_test == 0], x_test[:, 2][t_test == 0], \"x\", label = \"Features with t label = 0\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7408b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = np.mean((model.predict(x_train) > 0.5) == t_train)\n",
    "print(f\"The accuracy over the train set has been {accuracy_train:.2%}\")\n",
    "util.plot(x_train, y_train, theta=model.theta)\n",
    "plt.legend((\"y=1\", \"y=0\", \"Decision Boundary\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = np.mean((model.predict(x_test) > 0.5) == t_test)\n",
    "print(f\"The accuracy over the test set has been {accuracy_test:.2%}\")\n",
    "util.plot(x_test, y_test, theta=model.theta)\n",
    "plt.legend((\"y=1\", \"y=0\", \"Decision Boundary\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679338f",
   "metadata": {},
   "source": [
    "(e) Using the validation set, estimate the constant $\\alpha$ by averaging your classier's predictions over all labeled examples in the validation set:\n",
    "$$\n",
    "\\alpha \\approx \\dfrac{1}{|V_{+}|}\\sum_{x^{(i)} \\in V_{+}}h(x^{(i)})\n",
    "$$\n",
    "Add code in src/p02cde_posonly.py to rescale your classifer's predictions from part (d)\n",
    "using the estimated value for $\\alpha$.\n",
    "\n",
    "Finally, using a threshold of $p(t^{(i)} = 1| x^{(i)}) = 0.5$, make three separate plots with the\n",
    "decision boundaries from parts (c)- (e) plotted on top of the test set. Plot $x_1$ on the\n",
    "horizontal axis and $x_2$ on the vertical axis, and use two different symbols for the positive\n",
    "$(t^{(i)} = 1)$ and negative $(t^{(i)} = 0)$ examples. In each plot, indicate the separating hyperplane\n",
    "with a red line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc39629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compute alpha\n",
    "set_V = x_valid[y_valid == 1]\n",
    "alpha = sum(model.predict(set_V))/len(set_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we scale our prediction by alpha\n",
    "accuracy_train = np.mean((model.predict(x_train)/alpha> 0.5) == t_train)\n",
    "print(f\"The accuracy over the train set has been {accuracy_train:.2%}\")\n",
    "util.plot(x_train, y_train, theta=model.theta, correction=alpha)\n",
    "plt.legend((\"y=1\", \"y=0\", \"Decision Boundary\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = np.mean((model.predict(x_test)/alpha > 0.5) == t_test)\n",
    "print(f\"The accuracy over the test set has been {accuracy_test:.2%}\")\n",
    "util.plot(x_test, y_test, theta=model.theta, correction=alpha)\n",
    "plt.legend((\"y=1\", \"y=0\", \"Decision Boundary\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d41e5",
   "metadata": {},
   "source": [
    "We see that the model now obtains an accuracy almost as good as the model trained with the true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44107d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
